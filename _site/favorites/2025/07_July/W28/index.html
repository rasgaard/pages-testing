<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Composable AI and (open!) Small Language Models</title>
    <link rel="stylesheet" href="/styles.css">
    
    
</head>

<body>
    <nav class="site-nav">
        <a href="/" class="site-name">Rasmus Aagaard</a>
        <div class="nav-links">
            <a href="/phd/status/">PhD</a>
            <a href="/blog/">Blog</a>
            <!--<a href="/favorites/">Favorites</a>-->
        </div>
    </nav>
    <main>
        <article>
            <h4>Do One Thing Well</h4>
<blockquote>
<p><a href="https://blog.dottxt.co/do-one-thing-well.html">https://blog.dottxt.co/do-one-thing-well.html</a></p>
</blockquote>
<p>Using LLMs for production-grade applications can be a massive headache. There's a constant battle between freedom and control that you have to carefully manage. Structured outputs has been a game-changer for reliably using LLMs as composable components in larger systems. Being certain of the structure of the outputs allows for vast extensibility and opens up a lot of doors in terms of systems engineering. That's why I really like what <a href="dottxt.co">.txt</a> is doing along with the philosophy that they have outlined in the linked post.</p>
<p>It's surprisingly hard to focus to do one thing and to that thing really well. Scope and feature creep are definitely very real phenomena. Their examples from how Unix composes tools together such as <code>cat</code>, <code>cut</code>, <code>head</code> and <code>sort</code> is amazing to me, realising that such simple yet composable interfaces are hard to design and implement.</p>
<p>I hope we reach a similar state, as motivated by the post, with LLMs and other AI systems. I like the thought of composable AI building blocks.</p>
<h4>SmolLM3: smol, multilingual, long-context reasoner</h4>
<blockquote>
<p><a href="https://huggingface.co/blog/smollm3">https://huggingface.co/blog/smollm3</a></p>
</blockquote>
<p>I have said it before and I will say it again: I really like small (language) models.
The team over at HuggingFace is doing amazing and important work towards truly open LLM development and I have so much respect for it.</p>
<p>Not only does it help the narrative for my upcoming PhD, i.e. small models can actually be good, but it also sets up practitioners, hobbyists and researchers with amazing models that they otherwise wouldn't have the resources to train themselves. Making these models accessible and open will inevitably lead to new products, findings and creative projects.</p>
<p>I'm excited to learn more about the benefits of small models. Projects like these make me hopeful that it's a promising direction to pursue.</p>

        </article>
    </main>
    
    
    <script>
        // Theme toggle functionality
        const theme = localStorage.getItem('theme') || 'light';
        document.documentElement.setAttribute('data-theme', theme);

        function toggleTheme() {
            const current = document.documentElement.getAttribute('data-theme');
            const next = current === 'light' ? 'dark' : 'light';
            document.documentElement.setAttribute('data-theme', next);
            localStorage.setItem('theme', next);
        }

        // Add keyboard shortcut (Ctrl+T or Cmd+T)
        document.addEventListener('keydown', (e) => {
            if ((e.ctrlKey || e.metaKey) && e.key === 't') {
                e.preventDefault();
                toggleTheme();
            }
        });
    </script>
</body>

</html>