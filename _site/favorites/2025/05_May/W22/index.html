<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Microdosing AI, Efficient Multilingual Model &amp; Bespoke Annotation Tooling</title>
    <link rel="stylesheet" href="/styles.css">
    
    
</head>

<body>
    <nav class="site-nav">
        <a href="/" class="site-name">Rasmus Aagaard</a>
        <div class="nav-links">
            <a href="/phd/status/">PhD</a>
            <a href="/blog/">Blog</a>
            <!--<a href="/favorites/">Favorites</a>-->
        </div>
    </nav>
    <main>
        <article>
            <h4>Danskerne og deres kunstige intelligens</h4>
<blockquote>
<p>https://www.weekendavisen.dk/kultur/danskerne-og-deres-kunstige-intelligens</p>
</blockquote>
<p>This article explores the use of ChatGPT amongst Danes. It appears to be perfectly normal to use ChatGPT for all kinds of personal issues and dilemmas. One of them says that it's a type of &quot;therapeutic microdosing&quot; which I thought was a good way to put it. It's very new for us to have this level of access to something so knowledgeable and personal, and I think we are still not fully aware of the implications. Another one of them compares it to &quot;Monopolet&quot; in which someone brings a dilemma for a group of people to discuss. That got me thinking: maybe you should really be asking ChatGPT &quot;Give me 5 completely different view points on the following issue I'm dealing with&quot; when asking it for advice.</p>
<h4>minishlab/potion-multilingual-128M</h4>
<blockquote>
<p>https://huggingface.co/minishlab/potion-multilingual-128M</p>
</blockquote>
<p>I admire the way that the <a href="https://minishlab.github.io/">MinishLab</a> approach their work. It seems like it's just two very talented people that execute ideas very well, and that's a joy to witness. I haven't had much of a reason to play around with their Model2Vec approach but I look forward to doing so. This model is a new multilingual model in their <em>potion</em> series of models.</p>
<h4>The Rehearsal: Season 2 finale</h4>
<blockquote>
<p>https://variety.com/2025/tv/reviews/the-rehearsal-season-2-finale-review-nathan-fielder-1236408785/</p>
</blockquote>
<p>Ever since I randomly decided to watch <em>Nathan for You</em> and then proceeding to binge watch the entire series in 2 days I have been a massive fan of Nathan Fielder's work. The season finale of <em>The Rehearsal</em> solidified my appreciation for his comedy and dedication to his craft. It is just so unique that I don't really know what to compare it to and I absolutely love it. If you have already watched it, I can highly recommend giving this mind-boggling <a href="https://www.reddit.com/r/TheRehearsal/comments/1kx0vxr/season_2_was_a_magic_trick/">analysis on Reddit</a> a read.</p>
<h4>How to design better AI apps</h4>
<blockquote>
<p>https://youtube.com/watch?v=WJoZK9sMwvw</p>
</blockquote>
<p>This video touches on something that I have been thinking about recently at work. We develop features that use LLMs, and as developers we have a tendency to wanting to 'shield' the user from all of the complexity that is going on under the hood. With LLMs it is a little bit different though. A lot of the functionality can be designed in plain english. If the prompt is entirely decided by the developer then everyone gets the same (boring) experience. There's potential for so much more if the developer simply provides the scaffolding around the prompt and let the user write it to their liking.</p>
<h4>Verbos Podcast</h4>
<blockquote>
<p>https://www.youtube.com/watch?v=pgMe-usiUpY</p>
</blockquote>
<p>It feels weird to mention as something I liked, since I'm in it, but I really enjoyed being a guest on <a href="https://verbospodcast.dk/">Verbos Podcast</a>. We talked about running machine learning models on the client, via the browser - a topic that I have been interested in for a little while now. Having to articulate why I found it interesting and how I got started actually helped me understand it a bit better myself. It totally ties into the MLOps way of thinking! It's just another way of making the model 'live' and actually be used. That ties really well into my overall interest in MLOps. That connection didn't occur to me until shortly before I joined the video call. If you're interested in getting started with Transformers.js I wrote up a short <a href="https://rasgaard.com/posts/getting-started-transformersjs/">Getting Started</a> post.</p>
<h4>Building Eval Tools with FastHTML</h4>
<blockquote>
<p>https://www.youtube.com/watch?v=fA4pe9bE0LY</p>
</blockquote>
<p>I have enjoyed writing bespoke tooling for annotations and evaluations over the past few months. After having a look at 'off-the-shelf' solutions, I was never quite convinced that any of them could solve my problems. My problem had specific needs, and the annotations and evals needed to be tailored as well. So it makes me happy to see that this approach is not only quite common but also highly recommended by people such as <a href="https://hamel.dev/">Hamel Husain</a>. I have been using Streamlit for all of my projects at work but this video has inspired me to go ahead and try out FastHTML for the next one.</p>

        </article>
    </main>
    
    
    <script>
        // Theme toggle functionality
        const theme = localStorage.getItem('theme') || 'light';
        document.documentElement.setAttribute('data-theme', theme);

        function toggleTheme() {
            const current = document.documentElement.getAttribute('data-theme');
            const next = current === 'light' ? 'dark' : 'light';
            document.documentElement.setAttribute('data-theme', next);
            localStorage.setItem('theme', next);
        }

        // Add keyboard shortcut (Ctrl+T or Cmd+T)
        document.addEventListener('keydown', (e) => {
            if ((e.ctrlKey || e.metaKey) && e.key === 't') {
                e.preventDefault();
                toggleTheme();
            }
        });
    </script>
</body>

</html>